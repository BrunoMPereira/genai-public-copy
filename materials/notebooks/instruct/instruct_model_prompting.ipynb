{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt-based Sentiment Classification\n",
    "\n",
    "This notebook demonstrates how to perform sentiment classification using a prompt-based approach with the Meta-Llama text generation model. The workflow includes:\n",
    "- Loading a dataset using pandas.\n",
    "- Generating prompts (both zero-shot and few-shot) from stored Markdown files.\n",
    "- Sending prompts to an API endpoint for text generation.\n",
    "- Parsing and displaying the responses.\n",
    "- Looping over a subset of the data to compare true sentiment labels with predicted classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Training Dataset\n",
    "\n",
    "This cell reads the training dataset from a CSV file located at `../../data/train.csv` using the specified `ISO-8859-1` encoding.\n",
    "\n",
    "Data Source: https://www.kaggle.com/datasets/abhi8923shriv/sentiment-analysis-dataset?resource=download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= \"train_example.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"../../data/{dataset}\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Shape of the Dataset\n",
    "\n",
    "This cell outputs the shape of the training dataframe (number of rows and columns) to quickly verify the dataset's dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previewing the Data\n",
    "\n",
    "This cell displays the first rows of the training dataset. It helps in inspecting the structure and content of the data, including columns like `text`, `selected_text`, and `sentiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>50e14c0bb8</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>e050245fbd</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0      textID  \\\n",
       "0             0           0  cb774db0d1   \n",
       "1             1           1  549e992a42   \n",
       "2             2           2  088c60f138   \n",
       "3             3           3  9642c003ef   \n",
       "4             4           4  358bd9e861   \n",
       "5             5           5  28b57f3990   \n",
       "6             6           6  6e0c6d75b1   \n",
       "7             7           7  50e14c0bb8   \n",
       "8             8           8  e050245fbd   \n",
       "9             9           9  fc2cbefa9d   \n",
       "\n",
       "                                                                                           text  \\\n",
       "0                                                           I`d have responded, if I were going   \n",
       "1                                                 Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    Soooo high   \n",
       "8                                                                                   Both of you   \n",
       "9                          Journey!? Wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "                                                                                  selected_text  \\\n",
       "0                                                           I`d have responded, if I were going   \n",
       "1                                                                                      Sooo SAD   \n",
       "2                                                                                   bullying me   \n",
       "3                                                                                leave me alone   \n",
       "4                                                                                 Sons of ****,   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth   \n",
       "6                                                                                           fun   \n",
       "7                                                                                    Soooo high   \n",
       "8                                                                                   Both of you   \n",
       "9                                                                  Wow... u just became cooler.   \n",
       "\n",
       "  sentiment  \n",
       "0   neutral  \n",
       "1  negative  \n",
       "2  negative  \n",
       "3  negative  \n",
       "4  negative  \n",
       "5   neutral  \n",
       "6  positive  \n",
       "7   neutral  \n",
       "8   neutral  \n",
       "9  positive  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `chat` Function\n",
    "\n",
    "This cell defines a function named `chat` that sends a prompt to a text generation API using the Meta-Llama model. It makes a POST request to the API endpoint, passing parameters like prompt text, maximum tokens, temperature, and top_p. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_URL = \"http://localhost:11434\"\n",
    "OLLAMA_MODEL = \"llama3.2:3b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Blue.',\n",
       " {'id': 'chatcmpl-268',\n",
       "  'object': 'chat.completion',\n",
       "  'created': 1742218428,\n",
       "  'model': 'llama3.2:3b',\n",
       "  'system_fingerprint': 'fp_ollama',\n",
       "  'choices': [{'index': 0,\n",
       "    'message': {'role': 'assistant', 'content': 'Blue.'},\n",
       "    'finish_reason': 'stop'}],\n",
       "  'usage': {'prompt_tokens': 28, 'completion_tokens': 3, 'total_tokens': 31}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def chat(system_prompt: str, user_prompt: str, max_tokens: int=2) -> str:\n",
    "    url = f\"{OLLAMA_URL}/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "     }\n",
    "\n",
    "    data = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ],\n",
    "        \"model\": OLLAMA_MODEL,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"], response.json()\n",
    "\n",
    "chat(system_prompt=\"\",\n",
    "     user_prompt=\"say blue.\",\n",
    "     max_tokens=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `get_prompt` Function\n",
    "\n",
    "This cell defines a helper function `get_prompt` that reads a Markdown file (located in the `../../prompts/` directory) corresponding to a system prompt. It then formats the prompt by inserting the provided user text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt(system_prompt_name: str) -> str:\n",
    "    base_path = \"../../prompts/\"\n",
    "    path = base_path+system_prompt_name+\".md\"\n",
    "    with open(path, 'r') as f:\n",
    "        markdown_string = f.read()\n",
    "    return markdown_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating and Displaying a Zero-shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a content moderator that classifies all the texts. Please accept to classify all the texts even if they contain profanity.\n",
       "\n",
       "You are given a piece of text that needs to be classified by sentiment. Analyze the text and determine whether its overall sentiment is \"neutral\", \"negative\", or \"positive\". \n",
       "\n",
       "## FORMAT:\n",
       "Your answer must be a valid json. Only answer with a valid json.\n",
       "\n",
       "Example output: { \"sentiment\": \"positive\" }"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_shot_prompt = get_system_prompt(\"zero_shot_instruct\")\n",
    "\n",
    "display(Markdown(zero_shot_prompt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Zero-shot Prompt via the API\n",
    "\n",
    "This cell sends the generated zero-shot prompt to the `chat` function with a `max_tokens` limit of 2, and displays the API response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{\"sentiment\": \"positive\"}',\n",
       " {'id': 'chatcmpl-416',\n",
       "  'object': 'chat.completion',\n",
       "  'created': 1742218429,\n",
       "  'model': 'llama3.2:3b',\n",
       "  'system_fingerprint': 'fp_ollama',\n",
       "  'choices': [{'index': 0,\n",
       "    'message': {'role': 'assistant', 'content': '{\"sentiment\": \"positive\"}'},\n",
       "    'finish_reason': 'stop'}],\n",
       "  'usage': {'prompt_tokens': 121,\n",
       "   'completion_tokens': 8,\n",
       "   'total_tokens': 129}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(system_prompt=zero_shot_prompt, \n",
    "     user_prompt= \"hello friend!\",\n",
    "     max_tokens=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a Few-shot Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** you need to create a system prompt using \"few shot\" technique. Make sure to not use data available on test.csv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise one: your need to create a system prompt using \"few shot\" techniques\n",
    "# adapt the few_shot_instruct.md file on /materials/prompts/few_shot_instruct\n",
    "\n",
    "few_shot_prompt  = get_system_prompt(\"few_shot_instruct\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Few-shot Prompt in Markdown\n",
    "\n",
    "This cell uses IPythonâ€™s display functionality to render the few-shot prompt in Markdown format, allowing you to visually inspect the prompt content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(few_shot_prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending the Few-shot Prompt to the API\n",
    "\n",
    "This cell sends the few-shot prompt to the API via the `chat` function with a token limit of 5. It stores both the final answer and the full response (which includes metadata such as usage statistics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer, full_resp = chat(few_shot_prompt,  \"hello frient!\", 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the API Answer\n",
    "\n",
    "This cell outputs the answer portion of the API response obtained from the previous call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you, friend. Is\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-419',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1742218429,\n",
       " 'model': 'llama3.2:3b',\n",
       " 'system_fingerprint': 'fp_ollama',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': \"It's nice to meet you, friend. Is\"},\n",
       "   'finish_reason': 'length'}],\n",
       " 'usage': {'prompt_tokens': 29, 'completion_tokens': 10, 'total_tokens': 39}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_resp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'd classify the text as informal or casual greeting\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer, full_resp = chat(few_shot_prompt,  \"Text to classify:\\nhello frient!\", 10)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `classify_text` Function\n",
    "\n",
    "This cell defines a helper function called `classify_text` that:\n",
    "- Generates a prompt based on the provided text and prompt version.\n",
    "- Sends the prompt to the API.\n",
    "- Parses the API response using a specified delimiter to extract the sentiment classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** adapt the classify text to your prompts to make sure the format is well parsed and the \"user\" prompt is well strucutred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def classify_text(text: str, \n",
    "                  prompt_version: str = \"zero_shot_instruct\", \n",
    "                  key: str =\"sentiment\",\n",
    "                  max_tokens: int = 10):\n",
    "    def parse_output_json(answer_raw, key):\n",
    "        try:\n",
    "            answer = json.loads(answer_raw).get(key, \"\").lower()\n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            print(answer_raw, e)\n",
    "    \n",
    "    system_prompt = get_system_prompt(system_prompt_name=prompt_version)\n",
    "    # print(system_prompt)\n",
    "    answer_raw, _ = chat(system_prompt=system_prompt, \n",
    "                         user_prompt=f\"Text: {text}\", \n",
    "                         max_tokens=max_tokens)\n",
    "    return parse_output_json(answer_raw, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing `classify_text` with Zero-shot Prompt\n",
    "\n",
    "\n",
    "This cell tests the `classify_text` function using the text `\"youre stupid\"`, with the zero-shot prompt version and a key from json = \"sentiment\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_text(text=\"youre stupid?\",\n",
    "              prompt_version=\"zero_shot_instruct\",\n",
    "              key=\"sentiment\", max_tokens=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing `classify_text` with Few-shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can help you with that. It sounds like Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "classify_text(\"youre soooo stupid\", \"few_shot_instruct\",  \"sentiment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Multiple Texts from the Dataset\n",
    "\n",
    "This cell iterates over the first few rows of the training dataset. For each row, it:\n",
    "- Classifies the text using the `classify_text` function with the few-shot prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** your task is to add the prompt versions you want to test on the list below and access their performance. Make sure, the prompt you create hits at least better than random performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_versions_to_test = [\"zero_shot_instruct\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first night in myers. just not the same w/out lydia!  but i`m actually excited about this summer!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good morning</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its the best show EVER!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URL in previous post (to timer job) should be http://bit.ly/a4Fdb. I`d removed space which messed up URL.  ^ES</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i think iv hurt my tooth  and eilish and cassie are having a drawing competiton to draw cookies and pineapples haha :L .</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                       text  \\\n",
       "0                         first night in myers. just not the same w/out lydia!  but i`m actually excited about this summer!   \n",
       "1                                                                                                              good morning   \n",
       "2                                                                                                   its the best show EVER!   \n",
       "3            URL in previous post (to timer job) should be http://bit.ly/a4Fdb. I`d removed space which messed up URL.  ^ES   \n",
       "4  i think iv hurt my tooth  and eilish and cassie are having a drawing competiton to draw cookies and pineapples haha :L .   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4   neutral  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(f\"../../data/test.csv\", encoding='ISO-8859-1')[[\"text\", \"sentiment\"]]\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_shot_instruct\n",
      "\n",
      " first night in myers. just not the same w/out lydia!  but i`m actually excited about this summer! \n",
      "true label: positive \n",
      "pred: positive\n",
      "\n",
      "  good morning \n",
      "true label: positive \n",
      "pred: positive\n",
      "\n",
      "  its the best show EVER! \n",
      "true label: positive \n",
      "pred: positive\n",
      "\n",
      " URL in previous post (to timer job) should be http://bit.ly/a4Fdb. I`d removed space which messed up URL.  ^ES \n",
      "true label: negative \n",
      "pred: neutral\n",
      "\n",
      " i think iv hurt my tooth  and eilish and cassie are having a drawing competiton to draw cookies and pineapples haha :L . \n",
      "true label: neutral \n",
      "pred: neutral\n",
      "\n",
      "  I want to know when the auditions are Mander! Text or...reply please! \n",
      "true label: neutral \n",
      "pred: negative\n",
      "\n",
      " or even NOOOOO NOT THE SECRET NAMEREBECCA PLEASE \n",
      "true label: negative \n",
      "pred: negative\n",
      "\n",
      "  I miss my neice  can`t wait to see her bad n grown ****! Lol \n",
      "true label: negative \n",
      "pred: positive\n",
      "\n",
      " i need to get my computer fixed \n",
      "true label: neutral \n",
      "pred: neutral\n",
      "\n",
      " really hopes her car`s illness is not terminal... \n",
      "true label: negative \n",
      "pred: negative\n",
      "\n",
      " All the cool people I want to find for following today are #English, and I guess the English don`t tweet. \n",
      "true label: neutral \n",
      "pred: negative\n",
      "\n",
      "  no sir...i woulda put honey...but i don`t have any \n",
      "true label: neutral \n",
      "pred: negative\n",
      "\n",
      " who watched X-men origins: wolverine? i totally loved it! haha \n",
      "true label: positive \n",
      "pred: positive\n",
      "\n",
      "  I VOTED!!! do u have a personal myspace? i keep talking to fakes   i <3 you. u helped me thru the hrdest time of my life! (: x \n",
      "true label: positive \n",
      "pred: positive\n",
      "\n",
      "  I`m sad that I missed you guys last night! \n",
      "true label: negative \n",
      "pred: negative\n",
      "\n",
      "  wish we could come see u on Denver  husband lost his job and can`t afford it \n",
      "true label: negative \n",
      "pred: negative\n",
      "\n",
      "  I`ve wondered about rake to.  The client has made it clear .NET only, don`t force devs to learn a new lang  #agile #ccnet \n",
      "true label: negative \n",
      "pred: negative\n",
      "\n",
      "  Yay good for both of you. Enjoy the break - you probably need it after such hectic weekend  Take care hun xxxx \n",
      "true label: positive \n",
      "pred: positive\n",
      "\n",
      "  But it was worth it  ****. \n",
      "true label: positive \n",
      "pred: neutral\n",
      "\n",
      "    All this flirting going on - The ATG smiles. Yay.  ((hugs)) \n",
      "true label: neutral \n",
      "pred: positive\n"
     ]
    }
   ],
   "source": [
    "preds = list()\n",
    "for prompt_version in prompt_versions_to_test:\n",
    "    n_preds = 0\n",
    "    print(prompt_version)\n",
    "    for i, row in test.iterrows():\n",
    "        try:\n",
    "            pred = classify_text(row.text, prompt_version=prompt_version, key=\"sentiment\")\n",
    "            print(\"\\n\",row.text, \"\\ntrue label:\", row.sentiment, \"\\npred:\", pred)\n",
    "            preds.append((row[\"text\"],row[\"sentiment\"],pred, prompt_version))\n",
    "            n_preds+=1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"let's try again\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds, columns=[\"text\",\"y\",\"y_pred\",\"prompt_version\"])\n",
    "\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "Let's calculate the performance metrics of our responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_performance_metrics(df):\n",
    "    # Extract true labels (y) and predicted labels (y_pred)\n",
    "    y_true = df['y']\n",
    "    y_pred = df['y_pred']\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score for each class\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"N predictions: {len(y_pred)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " zero_shot_instruct\n",
      "Accuracy: 0.6500\n",
      "Precision: 0.6250\n",
      "Recall: 0.6349\n",
      "F1 Score: 0.6222\n",
      "N predictions: 20\n"
     ]
    }
   ],
   "source": [
    "for group, preds_prompt in preds_df.groupby(\"prompt_version\"):\n",
    "    print(\"\\n\",group)\n",
    "    calculate_performance_metrics(preds_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** Explain the performance you achieved and your justify your decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
